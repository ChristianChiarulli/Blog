{"componentChunkName":"component---src-templates-blog-post-jsx","path":"/Deepspeech/01-Deepspeech-basics/","result":{"data":{"markdownRemark":{"id":"4e284529-8523-5a96-a4e2-747aedade937","html":"<h2>What is Deepspeech</h2>\n<p>From Mozilla's github repo for deepspeech:</p>\n<p>\"DeepSpeech is an open source Speech-To-Text engine, using a model trained by machine learning techniques based on Baidu's Deep Speech research paper. Project DeepSpeech uses Google's TensorFlow to make the implementation easier.\"</p>\n<h2>Virtual environment</h2>\n<p>First let's create a virtual environment for deepspeech</p>\n<code-fence lang=\"null\" null>\n    <textarea vue-slot=\"code\">\n      conda create -n ds python=3.8\n\nconda activate deepspeech\n    </textarea>\n    </code-fence>\n  \n<h2>Install deepspeech</h2>\n<p>The only required package is deepspeech</p>\n<code-fence lang=\"null\" null>\n    <textarea vue-slot=\"code\">\n      pip install deepspeech\n    </textarea>\n    </code-fence>\n  \n<h1>Download Model</h1>\n<p>A pre-trained english model is available for download</p>\n<code-fence lang=\"null\" null>\n    <textarea vue-slot=\"code\">\n      curl -LO https://github.com/mozilla/DeepSpeech/releases/download/v0.6.1/deepspeech-0.6.1-models.tar.gz\n\ntar xvf deepspeech-0.6.1-models.tar.gz\n    </textarea>\n    </code-fence>\n  \n<h1>Download audio files</h1>\n<p>You can download some example audio files</p>\n<code-fence lang=\"null\" null>\n    <textarea vue-slot=\"code\">\n      curl -LO https://github.com/mozilla/DeepSpeech/releases/download/v0.6.1/audio-0.6.1.tar.gz\n\ntar xvf audio-0.6.1.tar.gz\n    </textarea>\n    </code-fence>\n  \n<h1>Run inference</h1>\n<p>We can now transcribe the audio file</p>\n<code-fence lang=\"null\" null>\n    <textarea vue-slot=\"code\">\n      deepspeech --model deepspeech-0.6.1-models/output_graph.pbmm --audio audio/2830-3980-0043.wav\n    </textarea>\n    </code-fence>\n  \n<p>If you ran the above command you should see something like \"experience proofsless\" if you are using the same model as me</p>\n<p>So not perfect, but we can try it out on our own voice as well</p>\n<h1>Record a wav file</h1>\n<p>For deepspeech to run inference correctly you will need to record your voice with some specific parameters.</p>\n<ul>\n<li>Sampling rate: 16 kHz</li>\n<li>Channel: 1</li>\n<li>Bit rate: 256 kb/s</li>\n</ul>\n<p>We can achieve this using the <code class=\"language-text\">sox</code> package</p>\n<p>If you're on Ubuntu:</p>\n<code-fence lang=\"null\" null>\n    <textarea vue-slot=\"code\">\n      sudo apt install sox\n    </textarea>\n    </code-fence>\n  \n<p>Arch Linux:</p>\n<code-fence lang=\"null\" null>\n    <textarea vue-slot=\"code\">\n      yay -S sox\n    </textarea>\n    </code-fence>\n  \n<p>Mac:</p>\n<code-fence lang=\"null\" null>\n    <textarea vue-slot=\"code\">\n      brew install sox\n    </textarea>\n    </code-fence>\n  \n<p>After installing <code class=\"language-text\">sox</code> you should have access to the <code class=\"language-text\">rec</code> command, we will use this to record our voice</p>\n<p>To begin recording you voice enter the following command</p>\n<code-fence lang=\"null\" null>\n    <textarea vue-slot=\"code\">\n      rec -r 16k -c 1 my_recording.wav\n    </textarea>\n    </code-fence>\n  \n<p>To make sure you have recorded the audio in the proper format we can install another package called <code class=\"language-text\">mediainfo</code> and run it like so:</p>\n<code-fence lang=\"null\" null>\n    <textarea vue-slot=\"code\">\n      mediainfo my_recording.wav\n    </textarea>\n    </code-fence>\n  \n<p>You should see an output similar to the following:</p>\n<code-fence lang=\"null\" null>\n    <textarea vue-slot=\"code\">\n      General\nComplete name                            : my_recording.wav\nFormat                                   : Wave\nFile size                                : 64.0 KiB\nDuration                                 : 2 s 48 ms\nOverall bit rate mode                    : Constant\nOverall bit rate                         : 256 kb/s\n\nAudio\nFormat                                   : PCM\nFormat settings                          : Little / Signed\nCodec ID                                 : 1\nDuration                                 : 2 s 48 ms\nBit rate mode                            : Constant\nBit rate                                 : 256 kb/s\nChannel(s)                               : 1 channel\nSampling rate                            : 16.0 kHz\nBit depth                                : 16 bits\nStream size                              : 64.0 KiB (100%)\n    </textarea>\n    </code-fence>\n  \n<h2>Run inference</h2>\n<p>Now we can run inference on our own voice data</p>\n<code-fence lang=\"null\" null>\n    <textarea vue-slot=\"code\">\n      deepspeech --model deepspeech-0.6.1-models/output_graph.pbmm --audio my_recording.wav\n    </textarea>\n    </code-fence>\n  \n<h2>Wrapping up</h2>\n<p>In the next article I'll go over running inference on a GPU</p>","excerpt":"What is Deepspeech From Mozilla's github repo for deepspeech: \"DeepSpeech is an open source Speech-To-Text engine, using a model trained byâ€¦","frontmatter":{"title":"Deepspeech basics","tags":["deepspeech"],"image":{"childImageSharp":{"resize":{"src":"/static/86a12aba2f2bc50aedd3e00976f6edbc/a8734/mozilla-deepspeech.png"},"fluid":{"base64":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAIAAAA7N+mxAAAACXBIWXMAACxKAAAsSgF3enRNAAACW0lEQVQoz2Po6d22b//VVatPTp6ya8aMPTNn7YuOmSYhma2jW2FgWKVvAEGVhoY1QIaeQaWjZbu9eWuA4+RAj1kMe/deff/+y9u3n2/cePbo0Zvnzz/s3XcVaEpk5FQNzTJDo2qgHl39CnfbXlebbnvL9nC3WRHOM7w9Z6vEr2Lo6d0KVL1s+bFp0/fMX3BwwYJD8+Yd3LDxbHzCTHWNUqBmPf1KI6PaIOepwa4zAt1mBLlMC3ecbBq6iCdnM4OOTrmWdrmObqWuXqW2TjkQAR0MJHX1K/VAqEJHr9zessPNZ66n+4wAl6kOvnMd/ObKJq/hzd7MAHSViUm9vX2vnj7ch1UG+pX6+pVm5s0WFq1WNp1eLlOV4ldqRC2z8ZsrkLWJP3MTf8YmIINBT6/CzKLVyWOGkUk90Cp9w2oDvQoNqxYD205nt+lOnjOcPWY4uU8XS13Hl71ZMHMjX/pmnqoN3A3rBdI2MejrlZvZ91p7zzaz6wZpNqgy1C0XD5unGLPcznWKtdtUG4+pOhHzBNI28Gdu5M/YKJCykX3yOsbVa3iLNjAYWbZq+c+WjV1u6jHNyKnfxLbL0GWiUOpawbR1en6zVIMXKiUv4O5fxZ+2QSBjPX/mer689cyL1jCtWsM6ew2DnscMyejlAqnrtL1naPnOlotcKhu+VDBlrWDyGuHENYIJa7ma1zIvWSOQuYa3cg3LnDVsU9YANbMsAJEMIqkrRJJXiMaskAldKBW+RChhlUD2KrGY5aLxK/gKVovGreDoXMsyax134xr23rXMM9exTF/HOhWKADyB7ipZBOvFAAAAAElFTkSuQmCC","aspectRatio":1.9898989898989898,"src":"/static/86a12aba2f2bc50aedd3e00976f6edbc/5134e/mozilla-deepspeech.png","srcSet":"/static/86a12aba2f2bc50aedd3e00976f6edbc/06f82/mozilla-deepspeech.png 197w,\n/static/86a12aba2f2bc50aedd3e00976f6edbc/da7d7/mozilla-deepspeech.png 393w,\n/static/86a12aba2f2bc50aedd3e00976f6edbc/5134e/mozilla-deepspeech.png 786w,\n/static/86a12aba2f2bc50aedd3e00976f6edbc/7a32a/mozilla-deepspeech.png 1179w,\n/static/86a12aba2f2bc50aedd3e00976f6edbc/6c0d9/mozilla-deepspeech.png 1572w,\n/static/86a12aba2f2bc50aedd3e00976f6edbc/b9295/mozilla-deepspeech.png 3690w","sizes":"(max-width: 786px) 100vw, 786px"}}}}}},"pageContext":{"slug":"/Deepspeech/01-Deepspeech-basics/","prev":{"node":{"fields":{"slug":"/Deepspeech/02-Deepspeech-gpu/"},"frontmatter":{"title":"Deepspeech using a GPU","tags":["deepspeech"]}}},"next":{"node":{"fields":{"slug":"/Linux/02-Create-User/"},"frontmatter":{"title":"Creating users","tags":["linux"]}}}}},"staticQueryHashes":["3649515864"]}